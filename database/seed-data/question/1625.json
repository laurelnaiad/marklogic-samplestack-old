{"Body":"<p>I am shocked that Linguists have not given a reasonably small canonical computationally precise representation of any natural language yet, so I wrote a recent <a href=\"http://english.stackexchange.com/questions/32447/is-there-an-ebnf-that-covers-all-of-english/60761#60761\">EL&amp;U post to explain how one does this for English</a>. I know that this grammar (or a small modification if I forgot something) covers all New York Times English, and all artificial highly embedded sentences, leaving out only:</p>\n\n<ul>\n<li>Idioms and weird constructions: \"How do you do?\", \"hello, dear.\", \"Okeh, oops!\", etc</li>\n<li>Tense-matching: this is a local finite property, and it doesn't touch the embedding structure. It is a distracting complication. I ignored it.</li>\n<li>Subject-verb matching: again not difficult, but distracting.</li>\n<li>Pronoun-reference: \"With a broom, John walked on the floor, beating it.\", what does \"it\" refer to? This is a very interesting linguistic question which I ignore.</li>\n<li>General \"and\" and \"or\": The and rules are cut-and-paste for different kinds of objects, debugging (ADVERB \"and\" ADVERB), (ADJECTIVE and ADJECTIVE), (PREPISH and PREPISH), etc, is tedious, so I skipped this.</li>\n<li>Verb ellipsis: I am not sure when this appears in the NYT, I have not seen an example yet. Verb ellipses can be implemented on the parser level, but at the rule level it's very annoying.</li>\n</ul>\n\n<p>The central possibly new idea that I used is the notion of a commutative context-free grammar. A commutative context-free grammar allows a string of nonterminals to move to different positions in the sentence before expanding. I will illustrate with a sentence with two movable ADVERB phrases, a subject and a verb. At some stage in the generation, it looks like this:</p>\n\n<blockquote>\n  <p>ADVERB+ ADVERB+ ADVERB+ (SUBJECT) (VERB OBJECT) </p>\n</blockquote>\n\n<p>In the next stages, I can move ADVERB+ to the right, so long as I don't go inside regions enclosed by parentheses. So I might get</p>\n\n<blockquote>\n  <p>ADVERB+ (the ADJ[] man ) ADVERB+ (takes the box) ADVERB+</p>\n</blockquote>\n\n<p>The ADVERB is a production that includes anything that attaches to the verb, including \"if\" clauses, initial \"yes\"/\"no\", and prepositional phrases that modify the action, as opposed to modifying the noun. At a later stage of production, the ADVERBs resolve to verb arguments, adverb words, or gerund phrases. So in a few steps, you get</p>\n\n<blockquote>\n  <p>With a broom (the tall man) to the big monster (takes the box) with a limp.</p>\n</blockquote>\n\n<p>Then you drop parentheses and introduce commas as conventional, to get:</p>\n\n<blockquote>\n  <p>With a broom, the tall man, to the big monster takes the box, with a limp.</p>\n</blockquote>\n\n<p>The point of this structure is to capture the commutativity of ADVERB position in a phrase. These really can appear anywhere, and often do in poetic work, although there are style conventions in English which tends to place them at canonical positions.</p>\n\n<p>This idea produces a very compact BNF for the phrase structure of English, and explains why other methods don't. The commutativity produces a large number of different nodes if you ignore it. I will point out that the parse description that this generates for the sentence is the same in all permutation of the ADVERBs. It's still a parse tree abstractly, but the tree is not contiguously represented in the sentence. Some arguments far away are bound to distant objects.</p>\n\n<p>There is always a position for the ADVERBs (after the verb) where if you force the writer to place them all there, the grammar becomes context free. If you restrict the ADVERBs to the very beginning too, you can also make it context free while still producing the ADVERBs from the verb, using the following trick:</p>\n\n<p>define a single nonterminal symbol: ADVERBLIST_SUBJECT_VERB_ADVERBLIST, and have context free rules that spit out ADVERBs on both sides, then when you are done spitting out ADVERBs, break it into SUBJECT ADVERBLIST_VERB_ADVERBLIST, then spit out ADVERBs on both sides, then resolve ADVERBLIST_VERB_ADVERBLIST into a VERB. This allows you to artificially remove commutativity, at the cost of introducing more parse levels into the grammar. If you do it wrong, you can easily introduce new parsing ambiguity that isn't there in the original sentence.</p>\n\n<p>Aside from being counterintuitive, a context-free reduction doesn't match the arguments to the verb the correct way, which is independent of their position, this trick also doesn't work in general. If you have two separate commutative lists, a list of ADJECTIVES and ADVERBs, these can commute past each other, so that if you force the grammar to be context free, you requiring an ever-growing number of nonterminals to represent the different permutations. You can probably parse all the New York Times with only a few permutations, since good style places the ADJECTIVE close to the noun it modifies, but this commutativity leads a combinatorial explosion in the representation of English that suggests that the reason is that the commutative grammar is not context free.</p>\n\n<h3>Formal Description</h3>\n\n<p>While one can define commutative grammars in extreme generality, I will restrict myself to the ones useful in English. The primitive commutation rule is a production of the form:</p>\n\n<blockquote>\n  <p>A+ B: B A+</p>\n</blockquote>\n\n<p>And likewise for all + marked variables with all unplussed variables. This allows the plus variables to move rightward, and I place them at the leftmost position they can occur.</p>\n\n<p>This production is not context free, it takes two objects to two other objects in the other order. But it isn't going hog-wild either--- the number and type of nonterminal symbols is preserved during this transformation--- it doesn't wreck the tree structure completely, it only permutes the order of the nonterminals, and the moment you expand \"B\" into something in parentheses, say:</p>\n\n<blockquote>\n  <p>B: (P Q)</p>\n</blockquote>\n\n<p>Then A no longer is allowed to commute with P and Q. So the commutativity is at each nesting level individually.</p>\n\n<p>I define a language to be commutative context-free if all comutative objects can be generated, commuted, and resolved into unplussed-variables before any other rules are applied. Further, I will only allow them to move in one direction, by convention to the right, since this is no loss of generality in the cases I am considering. Finally, I will require that any further expansion of nonterminals will always be enclosed in parentheses which provide a firm boundary to any commuting variables introduced at a deeper nesting level, so that objects at a lower level will never commute out of their level.</p>\n\n<h3>Questions</h3>\n\n<ol>\n<li>Is the commutative CFG in the mathematical linguistics literature? </li>\n<li>Does anyone see a proof that the commutative CFG is strictly stronger than CFG (I am pretty sure this is true)?</li>\n</ol>\n", "Id":"1625", "LastEditorUserId":"443", "Title":"Is the commutative CFG in the mathematical linguistics literature?", "CreationDate":"2012-03-13T05:35:01.640", "OwnerUserId":"810", "PostTypeId":"1", "Tags":"<syntax><english><computational-linguistics><grammar-formalism>", "AnswerCount":"1", "comments":[], "LastEditDate":"2013-01-09T23:36:17.833", "LastEditedUser":{"UpVotes":"434", "WebsiteUrl":"http://scholar.google.com/citations?user=DQ0tWyAAAAAJ&hl=en", "Id":"443", "AccountId":"33739", "CreationDate":"2011-10-23T03:42:22.710", "AboutMe":"<p>My name is Ivan Zakharyaschev, Иван Захарьящев, imz.</p>\n\n<p>Also, 632305222316434.</p>\n", "Age":"31", "Location":"Moscow, Russia", "DownVotes":"9", "Views":"8", "Reputation":"184", "DisplayName":"imz -- Ivan Zakharyaschev", "LastAccessDate":"2014-01-05T15:10:02.970"}, "ViewCount":"330", "LastActivityDate":"2013-01-09T23:36:17.833", "Score":"2", "CommentCount":"5", "OwnerUser":{"UpVotes":"39", "WebsiteUrl":"", "Id":"810", "AccountId":"528458", "CreationDate":"2012-03-03T03:39:07.707", "AboutMe":"<p>Everett is right. Chomsky was wrong. I want to know how recursion spread from Greece through the old world, and it seems we will find out. I am also curious about simpler examples of recursion, like list making.</p>\n\n<p>I mostly blindly follow Gell-Mann and agree with Joseph Greenberg about superfamilies and mass-comparison. I don't see any reason that the mass-comparison method cannot be made rigorous with good statistics.</p>\n\n<p>I like formal grammars, and I don't believe I understand something unless I can program a computer to understand it the same as me. My linguistic goal today is to write a good English parser. I think I can do at least marginally better than current parsers, which seem to be weighed down with theoretical cruft. Maybe it'll read a newspaper, maybe not. I hope to find out soon enough.</p>\n", "Age":"41", "Location":"New York City", "DownVotes":"0", "Views":"92", "Reputation":"481", "DisplayName":"Ron Maimon", "LastAccessDate":"2014-01-02T00:11:46.293"}}