{"Body":"<p>As you correctly note, ambiguity is rampant in natural language and whatever data structure is used for parsing in ambiguous grammars must somehow represent a large number of possible derivations.</p>\n\n<p>Despite this, it's not feasible to represent every possible derivation as an explicit parse tree, because the number of possible bracketings of a string is its <a href=\"https://en.wikipedia.org/wiki/Catalan_number\" rel=\"nofollow\">Catalan number</a>, exponential in its length.</p>\n\n<p>Which data structure is used to compactly represent ambiguity depends on the parsing algorithm chosen.</p>\n\n<p>I'll use the <strong><a href=\"https://en.wikipedia.org/wiki/CYK_algorithm\" rel=\"nofollow\">CKY algorithm</a></strong> as an example, as the way in which it packs ambiguity is simple to describe.</p>\n\n<p>The CKY parsing algorithm implicitly represents ambiguity using a data structure called a chart. </p>\n\n<p>To focus on your question, I'll leave the description of the algorithm out, only describing how the data structure represents ambiguity. I'll leave a description of the algorithm itself to any NLP text or <a href=\"http://www.youtube.com/watch?v=hq80J8kBg-Y\" rel=\"nofollow\">the video from Chris Manning's Coursera course</a>.</p>\n\n<p>Suppose we're parsing a sentence with N words. The chart can be modelled as a two-dimensional array, in which each cell C[i,j] contains all non-terminals which words [i..j] of the input sentence can derive. </p>\n\n<p>For instance, in the below chart, cell C[0,3] contains all the non-terminals derivable from the words <em>Book the flight</em> using a particular grammar.</p>\n\n<p><img src=\"http://i.stack.imgur.com/FnfIJ.png\" alt=\"CKY chart\"></p>\n\n<p>The CKY algorithm builds up the chart bottom-up through <a href=\"https://en.wikipedia.org/wiki/Dynamic_programming\" rel=\"nofollow\">dynamic programming</a>, so that when the algorithm terminates, the cell C[0,N] contains all possible non-terminals with a yield of the words [0..N]. </p>\n\n<p>The key insight that allows the chart to implicitly represent all possible derivations is that any parse tree in which some constituent XP has the yield [i..j] is represented by the very same chart entry in the cell C[i,j].</p>\n\n<p>In the above chart, for example, the chart entry NP in cell C[1,3] implicitly belongs to <em>every parse tree</em> in which the words <em>the flight</em> at positions 1 and 2 is interpreted as an NP.</p>\n\n<p>If each production rule is associated with a probability (a probabilistic context-free grammar), then a <strong>decoding</strong> algorithm such as the <a href=\"https://en.wikipedia.org/wiki/Viterbi_algorithm\" rel=\"nofollow\">Viterbi algorithm</a> can be used to find the most likely parse given the chart.</p>\n\n<p>Other parsing algorithms for <a href=\"https://en.wikipedia.org/wiki/Context-free_grammar\" rel=\"nofollow\">CFGs</a>, such as the Earley algorithm, have analogous ways of packing ambiguity â€” in an <a href=\"https://en.wikipedia.org/wiki/Earley_parser\" rel=\"nofollow\">Earley parser</a>, for instance, a data structure called the agenda contains all possible parsing states for a prefix of the input sentence.</p>\n\n<p>It's also possible for a parsing algorithm to discard ambiguity. Since not every possible parse is a likely parse, massive efficiency gains can be realised by only preserving a number of likely parses at each step (a <em>greedy algorithm</em>).</p>\n\n<p>Finally, some parsing algorithms, such as the <a href=\"https://en.wikipedia.org/wiki/Edmonds%27_algorithm\" rel=\"nofollow\">Chu-Liu-Edmonds algorithm</a> for <a href=\"https://en.wikipedia.org/wiki/Minimum_spanning_tree\" rel=\"nofollow\">MST (minimum spanning tree)</a> parsing, do not really represent derivational ambiguity directly. In such algorithms, the set of all possible parses isn't actually stored and thus can't easily be recovered. Instead, the sentence is treated as a graph, with directed edges representing dependencies between words. A tree algorithm runs over this graph to find the maximum-scoring set of spanning dependency edges. </p>\n\n<p>This is sufficient because most parsing applications in NLP focus not on enumerating all parses, but on finding the best parse with respect to some figure of merit.</p>\n\n<p>Bibliography:</p>\n\n<p>McDonald, Ryan, et al. \"Non-projective dependency parsing using spanning tree algorithms.\" Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2005.</p>\n", "Id":"4620", "ParentId":"4619", "LastEditorUserId":"51", "CreationDate":"2013-10-05T09:04:11.510", "OwnerUserId":"746", "PostTypeId":"2", "comments":[], "LastEditDate":"2013-10-05T12:22:46.507", "LastEditedUser":{"UpVotes":"1436", "WebsiteUrl":"http://en.wiktionary.org/wiki/User:Hippietrail", "ProfileImageUrl":"http://i.stack.imgur.com/ExcaS.jpg", "Id":"51", "AccountId":"250783", "CreationDate":"2011-09-13T21:15:02.967", "AboutMe":"<p>Travelling armchair linguist.</p>\n\n<p>Never studied in an institution but read books and web with probably more breadth than depth.</p>\n\n<p>Always on the road surviving in a strange foreign language, currently Mongolian and Mandarin Chinese.</p>\n\n<p>And I collect dictionaries.</p>\n", "Location":"Beijing, China", "DownVotes":"65", "Views":"221", "Reputation":"4918", "DisplayName":"hippietrail", "LastAccessDate":"2014-01-18T09:27:54.697"}, "LastActivityDate":"2013-10-05T12:22:46.507", "Score":"4", "OwnerUser":{"UpVotes":"62", "WebsiteUrl":"http://www.overpunch.com", "Id":"746", "AccountId":"63513", "CreationDate":"2012-02-07T00:29:49.180", "AboutMe":"<p>I am a computational linguistics PhD candidate. But before that, long before that, I fell in love with languages.</p>\n\n<p>By the way, if you're addicted to Stack Exchange and use iOS, check out <a href=\"http://stackapps.com/questions/3673/stackwise-a-beautiful-way-to-browse-stack-exchange-sites\">Stackwise for iOS</a> and browse Stack Exchange beautifully.</p>\n", "Age":"28", "Location":"Sydney, Australia", "DownVotes":"12", "Views":"15", "Reputation":"1989", "DisplayName":"jogloran", "LastAccessDate":"2014-01-18T09:49:34.847"}}