{"comments":[], "Body":"<p>I don't know of a specific scoring method, but you could probably use a grapheme-to-phoneme conversion approach to make up a reasonable one without too much work.</p>\n\n<p>Say you have a pronunciation dictionary for each of your languages.  This maps orthographies to pronunciations:</p>\n\n<pre><code>TEST  t eh s t\nWRING r ih N\nBEAT  b iy t\n</code></pre>\n\n<p>You could use some kind of alignment algorithm to estimate alignments between the letters and phonemes (Note: below is just <em>one</em> possible, believable alignment):</p>\n\n<pre><code>T:t E:eh S:s T:t\nW:_ R:r I:ih N:_ G:N\nB:b E:iy A:_ T:t\n</code></pre>\n\n<p>Then a really trivial sort of measure might be to just compute the average number of phonemes that are matched to each grapheme and vice versa.  The expectation here being that a 'phonemic' system will tend to have more one-to-one mappings, while a mess like English will tend to have quite a few one-to-many / many-to-one mappings.</p>\n\n<p>My guess would be that even this sort of trivial approach would mark a pretty clear difference between say, English and Spanish (I don't know Serbo-Croatian).</p>\n", "Id":"2208", "ParentId":"2207", "CreationDate":"2012-07-04T05:49:30.100", "Score":"1", "PostTypeId":"2", "OwnerUserId":"1159", "LastActivityDate":"2012-07-04T05:49:30.100", "OwnerUser":{"UpVotes":"1", "DownVotes":"0", "Id":"1159", "AccountId":"35425", "Views":"0", "Reputation":"144", "CreationDate":"2012-07-04T05:11:59.663", "DisplayName":"si28719e", "LastAccessDate":"2012-07-10T06:05:08.883"}}