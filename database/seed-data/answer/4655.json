{"OwnerUser":{"UpVotes":"184", "WebsiteUrl":"", "Location":"Australia", "Id":"363", "DownVotes":"11", "AccountId":"948668", "Views":"67", "Reputation":"3682", "CreationDate":"2011-10-02T11:34:38.250", "DisplayName":"Gaston Ãœmlaut", "LastAccessDate":"2014-01-18T22:46:37.857", "AboutMe":"<p>I am a rock climber &amp; a linguist.</p>\n"}, "comments":[], "Body":"<p>This is a complex topic but here's an attempt at an answer. My background is in describing and documenting relatively small, endangered languages, so I'll describe how it's done in that situation. I'll assume you have computers, software, internet, native speaking informants, recording equipment, and many years to spend on the work.</p>\n\n<p>Firstly, recorded texts are needed, which are transcribed typically using software such as <a href=\"http://tla.mpi.nl/tools/tla-tools/elan/\">ELAN</a>, and with much help from the native-speaking assistant. The resulting transcript should be time-aligned and have the following annotations at a minimum, each on its own tier:</p>\n\n<pre><code>*a phonemic reperesentation of the text\n*a gloss (a very brief definition)\n*a free translation\n</code></pre>\n\n<p>This is known as an <a href=\"https://en.wikipedia.org/wiki/Interlinear_gloss\">interlinear gloss</a> and is a standard analytical approach in linguistics. Here's an example (Western Desert language, Pama-Nyungan):</p>\n\n<pre><code>ngayulu  ngurra -kutu ya -nku\n1.sg.ERG home -ALL    go -FUT\n'I'm going homewards'\n</code></pre>\n\n<p>Another commonly included tier is a part of speech description for each lexical item (presupposing an analysis of the language).</p>\n\n<p>Next this data would be imported into a tool such as <a href=\"http://www-01.sil.org/computing/toolbox/\">Toolbox</a>, <a href=\"http://fieldworks.sil.org/flex/\">FLEx</a> or <a href=\"http://tshwanedje.com/tshwanelex/\">TshwanaLex</a>. These tools then construct a database of the lexical items. The entry for each item will include the part of speech assignment, the gloss, a fuller definition, and can include many other pieces of information about the entry. These tools typically also enable creating a <a href=\"https://en.wikipedia.org/wiki/Key_Word_in_Context\">KWIC (key word in context) concordance</a> which facilitates analysis of the text to discover the full range of meanings and uses of an item.</p>\n\n<p>This <a href=\"https://en.wikipedia.org/wiki/Lexical_database\">'lexical database'</a> will typically be formatted using <a href=\"http://ses.library.usyd.edu.au/bitstream/2123/6936/1/RAL-chapter-28.pdf\">FOSF (Field-Oriented Standard Format), aka backslash codes</a>, or at least will enable export/import using FOSF. FOSF consists of a backslash '\\' combined with an arbitrary alphanumeric string, followed by the information it categorises. A fairly typical if basic entry would look like this (entry for the word 'papa', Western Desert language):</p>\n\n<pre><code>\\lx papa\n\\pos noun\n\\def dog\n\\syn maliki\n\\xv papangku wati patjarnu\n\\xe the dog bit the man\n\\so JS\n</code></pre>\n\n<p>The codes: \\lx = headword (this would also indicate start of a new entry), \\pos = part of speech, \\def = definition, \\syn = synonym, \\xv = vernacular example, \\xe = english gloss of example, \\so = source.</p>\n\n<p>Entries such as this one can have a much more complex structure, including multiple senses. Each sense subentry would begin with a line such as \\se1 (for the first sense), followed by its own \\def, \\syn, etc lines within the entry, as appropriate.</p>\n\n<p>There is a variety of software that can take a regularly-structured FOSF lexical database and convert it into a nicely formatted dictionary. One easy to use software to do this that is currently popular is <a href=\"http://www.lexiquepro.com\">Lexique Pro</a>, although ToolBox and FLEx can also do this conversion. </p>\n", "Id":"4655", "ParentId":"4623", "CreationDate":"2013-10-08T10:20:42.977", "Score":"6", "PostTypeId":"2", "OwnerUserId":"363", "LastActivityDate":"2013-10-08T10:20:42.977", "CommentCount":"3"}