{"Body":"<p>I read a paper called <a href=\"http://www.fon.hum.uva.nl/paul/papers/BoersmaHamannLoans35.pdf\" rel=\"nofollow\">Loanword adaptation as first-language phological perception</a> by Boersma and Hamann for a Phonology class project last semester. That introduced me to both the idea of a productive perception and the idea of a learning algorithm for OT. I think these two ideas (along with <a href=\"http://en.wikipedia.org/wiki/Optimality_theory\" rel=\"nofollow\">Optimality Theory</a>) may help explain the phenomenon you are investigating.</p>\n\n<p>The assumption in a lot of literature is that perception is completely faithful, i.e. what people perceive is a 1:1 relation of the incoming soundwave. Productive perception says that this isn't true and that people's perceptions are based on their ingrained phonology. The Boersma/Hamann paper I linked earlier uses this idea to say that people intuitively transpose any foreign words into their own phonology during perception, explaining why loanwords are often pronounced differently from their source form (and indeed, from other native words with similar forms, thus either ruling out a production-only based explanation or requiring loanword-specific rules and constraints).</p>\n\n<p>This paper cites a 1997 paper by Boersma called <a href=\"http://www.fon.hum.uva.nl/paul/papers/learningVariation.pdf\" rel=\"nofollow\">How We Learn Variation, Optionality, and Probability</a>. I have not read this paper in full, so my understanding mostly comes from the summary included in the Boersma/Hamann paper I included above.</p>\n\n<p>Basically, Boersma claims that the constraints (normally used for mapping SR to phonetic form) are bidirectional and that they can be applied during perception as well as production. These constraints are then ranked by probability. For example, consider a cue constraint <code>*[ɛ]/e/</code>. During production this constraint would be understood as \"don't produce the phonologic form /e/ as the phonetic form [ɛ]\"; during perception as \"don't perceive [ɛ] as /e/\" (or generically, \"[ɛ] is not /e/\"). In English representing /e/ as [ɛ] (as opposed to the more faithful [e]) usually does not result in any loss of meaning and thus can be freely violated. These frequent violations would then lead <code>*[ɛ]/e/</code> to become lowly ranked. Contrast this with French where representing /e/ as [ɛ] <strong>does</strong> usually lead to a loss of meaning and thus such a constraint would be more heavily used and therefore become higher ranked.</p>\n\n<p>Now to tie it in with your question. Presumably one hears their name very often. So a learning algorithm like the one Boersma proposes would rank the constraints in such a way that one can readily distinguish their name during perception, even if the incoming phonetic form is damaged or has heavy interference (such as in a noisy room). It would also explain why people sometimes hallucinate hearing their name (or other common words) and rarely hallucinate uncommon or arcane words.</p>\n\n<p>Obviously, this is just one possibility but I hope I at least provided some interesting links.</p>\n\n<p><s>As for what it's called, perhaps <a href=\"http://www.wisegeek.com/what-is-selective-hearing.htm\" rel=\"nofollow\">selective hearing</a>?</s></p>\n", "Id":"2347", "ParentId":"2345", "LastEditorUserId":"1055", "CreationDate":"2012-08-04T04:07:46.300", "OwnerUserId":"1055", "PostTypeId":"2", "comments":[], "LastEditDate":"2012-08-06T05:42:48.203", "LastEditedUser":{"UpVotes":"102", "WebsiteUrl":"", "Location":"Seoul, South Korea", "Id":"1055", "DownVotes":"9", "AccountId":"1453460", "Views":"21", "Reputation":"1947", "CreationDate":"2012-05-29T05:50:57.073", "DisplayName":"acattle", "LastAccessDate":"2014-01-17T00:59:41.983", "AboutMe":"<p>I am currently studying for an MA in Computational Linguistics even though my background is not in linguistics. I discovered Computational Linguistics while receiving my B.A.Sc in Software Engineering when I built a basic bigram parser for an AI assignment. This caused me to become interested in linguistics and to take a few introductory level courses. I currently have completed my first year of my masters and am currently looking for a thesis topic.</p>\n"}, "LastActivityDate":"2012-08-06T05:42:48.203", "Score":"4", "CommentCount":"2", "OwnerUser":{"UpVotes":"102", "WebsiteUrl":"", "Location":"Seoul, South Korea", "Id":"1055", "DownVotes":"9", "AccountId":"1453460", "Views":"21", "Reputation":"1947", "CreationDate":"2012-05-29T05:50:57.073", "DisplayName":"acattle", "LastAccessDate":"2014-01-17T00:59:41.983", "AboutMe":"<p>I am currently studying for an MA in Computational Linguistics even though my background is not in linguistics. I discovered Computational Linguistics while receiving my B.A.Sc in Software Engineering when I built a basic bigram parser for an AI assignment. This caused me to become interested in linguistics and to take a few introductory level courses. I currently have completed my first year of my masters and am currently looking for a thesis topic.</p>\n"}}