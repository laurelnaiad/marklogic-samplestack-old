{"comments":[], "Body":"<p>The reason why trigrams can be considered powerful compared to n-grams of higher order, lies in the problem of data sparsity; when n is higher, data becomes increasingly sparse. Because of this, using trigrams is a good compromise which often yields good results.</p>\n\n<p>In a study by Chen and Goodman (1998), the effect of varying n-gram orders on the performance of a language model was compared. As expected, they found that 4-grams and 5-grams significantly outperform trigram models when using a very large data set (approximately 1e+06 sentences).</p>\n\n<p>I'm not sure where you could find a source stating that trigrams outperform other models, but if you cite Chen and Goodman you can at least say that higher order n-grams are only viable with large data sets.</p>\n\n<p>(Sorry I can't provide you with a link to this article, but here's the citation at least!)</p>\n\n<p>Chen, Stanley F. and Goodman, Joshua. An empirical study of smoothing techniques for language\nmodeling. Harvard University, Center for Research in Computing Technology, TR-10-98:1â€“63, 1998.</p>\n", "Id":"2772", "ParentId":"2654", "CreationDate":"2012-10-30T17:30:04.447", "Score":"5", "PostTypeId":"2", "OwnerUserId":"1452", "LastActivityDate":"2012-10-30T17:30:04.447", "OwnerUser":{"UpVotes":"4", "WebsiteUrl":"", "Location":"Groningen, Netherlands", "Id":"1452", "DownVotes":"0", "AccountId":"1943733", "Views":"2", "Reputation":"188", "CreationDate":"2012-10-30T17:13:14.697", "DisplayName":"Bjerva", "LastAccessDate":"2013-12-17T14:05:45.320", "AboutMe":"<p>Ph.D. student in Computational Semantics at the University of Groningen</p>\n"}}