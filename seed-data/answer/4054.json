{"Body":"<p>I assume you're dealing with audio data. Then your problem is that phonemes in actual speech are not discrete units and there is no single right answer to the question where the boundary between a consonant and a following vowel is located. For example, in the syllable <code>/pa/</code>, the articulators move away from the most consonant-like position where airflow is completely blocked (lips are closed) to a fully open position at the mid-point of <code>/a/</code>. The articulators need time for that, so there is a range of mid-points between the two sounds that you might want to consider as potential boundaries.</p>\n\n<p>When dealing with a sequence of an obstruent (a consonant such as <code>/p,t,f,z/</code>) and a vowel, common criteria are:</p>\n\n<ul>\n<li>onset/offset of stable formant pattern in the vowel</li>\n<li>rapid in-/decrease in intensity</li>\n<li>and sometimes onset/offset of voicing</li>\n</ul>\n\n<p>When dealing with a sequence of a sonorant (a consonant such as <code>/n,m,w/</code>) these criteria might be less or not at all useful. But a change in intensity and change in formant pattern will usually be observable. For example, approximant <code>/r/</code> (such as in standard American and British English) usually has a low third formant, so the boundary could be set at the midpoint of the trajectory of the third formant in a <code>/r/ + vowel sequence</code>.</p>\n\n<p>Here are two references you might find useful:</p>\n\n<ul>\n<li>Machac, Pavel and Radek Skarnitzl (2009). Principles of Phonetic Segmentation. Prague:\nEpocha.</li>\n<li>Wiget, Klaus, Laurence White, Barbara Schuppler, Izabelle Grenon, Oleysa Rauch, and\nSven L. Mattys (2010). How stable are acoustic metrics of contrastive speech rhythm?\nJournal of the Acoustical Society of America 127.3:1559-1569.</li>\n</ul>\n\n<p>The latter is not primarily about your topic but they give a good description of and more references for segmentation criteria.</p>\n\n<p>Before you start writing your own program you might also want to consider using or adapting existing solutions. There are some tools that use phonemic forced alignment, such as <a href=\"http://htk.eng.cam.ac.uk/\" rel=\"nofollow\">HTK</a>. Together with an acoustic model of the language you are working on and an orthographic transcription of the text, this produces a phonemic time-aligned transcription of an audio recording. Together with <a href=\"http://www.ling.upenn.edu/phonetics/p2fa/\" rel=\"nofollow\">P2FA</a>, which provides a wrapper and an acoustic model of American English, and outputs Praat TextGrids, I have achieved good results even for other varieties of English. You could also take a look at <a href=\"http://www.bas.uni-muenchen.de/Bas/BasMAUS.html\" rel=\"nofollow\">MAUS</a>, which provides a web interface for a small number of languages and also produces Praat TextGrids.</p>\n", "Id":"4054", "ParentId":"4053", "LastEditorUserId":"2278", "CreationDate":"2013-07-24T19:50:17.793", "OwnerUserId":"2278", "PostTypeId":"2", "comments":[], "LastEditDate":"2013-07-25T08:59:48.910", "LastEditedUser":{"UpVotes":"604", "WebsiteUrl":"", "DownVotes":"27", "Id":"2278", "AccountId":"1711803", "Views":"29", "Reputation":"1797", "CreationDate":"2013-07-22T17:11:57.903", "DisplayName":"robert", "LastAccessDate":"2014-01-19T00:31:56.677", "AboutMe":""}, "LastActivityDate":"2013-07-25T08:59:48.910", "Score":"1", "OwnerUser":{"UpVotes":"604", "WebsiteUrl":"", "DownVotes":"27", "Id":"2278", "AccountId":"1711803", "Views":"29", "Reputation":"1797", "CreationDate":"2013-07-22T17:11:57.903", "DisplayName":"robert", "LastAccessDate":"2014-01-19T00:31:56.677", "AboutMe":""}}