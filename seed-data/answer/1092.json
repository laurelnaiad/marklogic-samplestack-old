{"comments":[], "Body":"<p>As for prior art, there is quite a lot. Formal grammars use a theory of language to encode the grammar of a language. You can go through the links I gave <a href=\"http://linguistics.stackexchange.com/a/120/126\">when answering a related question</a>. ERG that jlovegren mentioned is one such example. Other examples would be <a href=\"http://www.cis.upenn.edu/~xtag/\" rel=\"nofollow\">XTAG</a> and <a href=\"http://decentius.aksis.uib.no/logon/xle.xml\" rel=\"nofollow\">XLE</a>, both of which have fairly comprehensive grammars for English, just like ERG, and <a href=\"http://openccg.sourceforge.net/\" rel=\"nofollow\">OpenCCG</a>, which, at the moment, does not have a comprehensive grammar for English, but has it for a few other languages.</p>\n\n<p>Statistical algorithms, these days, far out-perform hand-written grammars when it comes to \"understanding\" a sentence. However, the designers of most statistical parsers have designed their systems to make the \"best possible sense\" of every sentence, and so, are poor at detecting grammaticality.</p>\n\n<p>One system that is already used to detect grammaticality of sentences is <a href=\"http://www.abisource.com/projects/link-grammar/\" rel=\"nofollow\">Link-Grammar</a> which happens to be integrated into AbiWord.</p>\n\n<p>I could go on, but this should be enough to start with.</p>\n", "Id":"1092", "ParentId":"1090", "CreationDate":"2011-11-29T23:43:19.487", "Score":"3", "PostTypeId":"2", "OwnerUserId":"126", "LastActivityDate":"2011-11-29T23:43:19.487", "OwnerUser":{"UpVotes":"94", "DownVotes":"21", "Id":"126", "AccountId":"154977", "Views":"23", "Reputation":"1354", "CreationDate":"2011-09-14T15:07:55.557", "DisplayName":"prash", "LastAccessDate":"2014-01-18T18:45:53.780"}}