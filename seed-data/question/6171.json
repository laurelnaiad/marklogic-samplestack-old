{"OwnerUser":{"UpVotes":"1436", "WebsiteUrl":"http://en.wiktionary.org/wiki/User:Hippietrail", "ProfileImageUrl":"http://i.stack.imgur.com/ExcaS.jpg", "Id":"51", "AccountId":"250783", "CreationDate":"2011-09-13T21:15:02.967", "AboutMe":"<p>Travelling armchair linguist.</p>\n\n<p>Never studied in an institution but read books and web with probably more breadth than depth.</p>\n\n<p>Always on the road surviving in a strange foreign language, currently Mongolian and Mandarin Chinese.</p>\n\n<p>And I collect dictionaries.</p>\n", "Location":"Beijing, China", "DownVotes":"65", "Views":"221", "Reputation":"4918", "DisplayName":"hippietrail", "LastAccessDate":"2014-01-18T09:27:54.697"}, "comments":[], "Body":"<p>Often I want to make my own corpus of a new language I've become interested in.</p>\n\n<p>I'm very happy to make my own tools and have plenty of programming experience. I have made my own tool to gather plain text random samples from a specified language edition of Wikipedia and it has worked pretty well.</p>\n\n<p>But sometimes a language doesn't have its own Wikipedia, or its Wikipedia is too small or shows too many artefacts being heavy on articles on certain topics.</p>\n\n<p>What I would like is a tool that crawl the web and gather pages using only a certain language.</p>\n\n<p>It doesn't have to do anything linguistic, raw HTML is usable, plain Unicode text is better, but if it can also do things like word frequency, normalizing, lemmatizing, etc that would be a great bonus.</p>\n\n<p>My current language of interest is Mongolian written in the traditional script, which does indeed seem to have a large enough web presence.</p>\n\n<p>Is there a tool that could help me with this?</p>\n", "Id":"6171", "Title":"Tool for building a corpus by crawling the web?", "ViewCount":"29", "CreationDate":"2013-12-17T04:01:07.067", "Score":"0", "PostTypeId":"1", "OwnerUserId":"51", "LastActivityDate":"2013-12-17T04:01:07.067", "Tags":"<computational-linguistics><corpora><tools>"}