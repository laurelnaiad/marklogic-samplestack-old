{"Body":"<p>I've recently been tasked with programming a web crawler that searches through news articles for certain keywords--company names, for example--and then tries to determine if the article has a positive or negative slant. The web crawling portion is trivial but I feel that I've bitten off more than I can chew for the textual analysis portion.</p>\n\n<p>My current approach is detailed below. I'm wondering if it's a sensible way to do things, or if there are better methods to try.</p>\n\n<p>The crawler starts off by pulling the page's DOM. It then assumes that the actual \"article\" is within the paragraph <code>&lt;p&gt;</code> tags, so it reduces the data down to just that text. (This may be refined later on a per-website basis, but for now it works reasonably well). There are three input files: the aforementioned keywords, with words like \"Facebook\" or \"Google\", and then two wordlists, one containing positive words and the other containing negative.</p>\n\n<p>The program then crawls through each paragraph of text in search for the keywords. If it finds a keyword, it starts checking every word against both word list. A keyword has a weight for each webpage, starting at 0, and incrementing for positive words found in the paragraph, decrementing for negative words found. So if 5 positive words and 3 negative words are found accompanying a keyword, a weight of +2 is assigned. If the combined weight of all paragraphs is positive (or even above some cut-off) the article is deemed to view it in a positive light, and the opposite for a negative score.</p>\n\n<p>Obviously this approach brings some pretty huge issues. For example, a keyword (always a proper name) can be used once in an article, and the rest of the text may just refer to it as \"it\". I could make the scoping of the keyword per article (i.e., if the keyword is found anywhere in the page, then any paragraph containing listed words count toward the weight) but that brings it's own problems.</p>\n\n<p>I'm not a linguist, and I realize this problem is probably pretty high up as far as linguistic problems go. I'm not looking for a perfect solution, but I'd like to know if there is anything more I could be doing.</p>\n\n<p>Thanks for any feedback. I'm not sure if this is really appropriate for this stackexchange site, if it's not I'd like to know a better place.</p>\n", "Id":"3938", "LastEditorUserId":"51", "Title":"sentiment analytics", "CreationDate":"2013-06-30T23:57:49.777", "OwnerUserId":"2210", "PostTypeId":"1", "Tags":"<computational-linguistics><nlp><software><sentiment-analysis>", "AnswerCount":"2", "comments":[], "LastEditDate":"2013-07-02T14:24:26.217", "LastEditedUser":{"UpVotes":"1436", "WebsiteUrl":"http://en.wiktionary.org/wiki/User:Hippietrail", "ProfileImageUrl":"http://i.stack.imgur.com/ExcaS.jpg", "Id":"51", "AccountId":"250783", "CreationDate":"2011-09-13T21:15:02.967", "AboutMe":"<p>Travelling armchair linguist.</p>\n\n<p>Never studied in an institution but read books and web with probably more breadth than depth.</p>\n\n<p>Always on the road surviving in a strange foreign language, currently Mongolian and Mandarin Chinese.</p>\n\n<p>And I collect dictionaries.</p>\n", "Location":"Beijing, China", "DownVotes":"65", "Views":"221", "Reputation":"4918", "DisplayName":"hippietrail", "LastAccessDate":"2014-01-18T09:27:54.697"}, "ViewCount":"106", "LastActivityDate":"2013-07-02T14:24:26.217", "Score":"3", "OwnerUser":{"UpVotes":"0", "WebsiteUrl":"http://x64.co", "Id":"2210", "AccountId":"466892", "CreationDate":"2013-06-30T23:44:45.690", "AboutMe":"<p>I'm a programmer and hardware enthusiast, studying electrical engineering.</p>\n", "Age":"22", "Location":"Tallahassee, FL", "DownVotes":"0", "Views":"0", "Reputation":"16", "DisplayName":"Corey", "LastAccessDate":"2013-08-09T14:43:21.917"}}